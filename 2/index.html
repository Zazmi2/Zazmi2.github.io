<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Image Processing Project</title>
    <style>
    /* Modal styles for zoom effect */
    .modal {
        display: none;
        position: fixed;
        z-index: 1000;
        padding-top: 60px;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        overflow: auto;
        background-color: rgba(0,0,0,0.9);
    }

    .modal-content {
        display: block;
        margin: auto;
        max-width: 90%;
        max-height: 90%;
    }

    .close {
        position: absolute;
        top: 30px;
        right: 45px;
        color: #fff;
        font-size: 40px;
        font-weight: bold;
        cursor: pointer;
    }

    .close:hover,
    .close:focus {
        color: #bbb;
        text-decoration: none;
        cursor: pointer;
    }

    /* Optional: cursor style for zoomable images */
    img.zoomable {
        cursor: zoom-in;
        transition: transform 0.2s;
    }
    </style>
</head>
<body>

    <h1>Image Processing Final Report</h1>

    <h2>Part 1: Filters and Edges</h2>

    <h3>1.1 Convolution with NumPy</h3>
    <p>I implemented convolution using only NumPy. The outputs were compared with <code>scipy.signal.convolve2d</code>. Runtime was measured using the notebook output. The runtime with four for loops is 2min and 16sec. The runtime with two for loops is 12.1 seconds. For comparison, using scipy's conv2d took 0.8 seconds.These tests used the box filter for the kernel. My implementation for padding utlizes np.pad and padds it with one layer of ones around the image. Techincally it can't be adjust but can do different implementations for the padding. I modified the padding in my conv2d method to be more versatile in my part 2 implementations. Scipy's padding  provides handling for boundary conditions such as `'symm'` (mirroring), `'wrap'`, and `'fill'`, making it more flexible and efficient for most practical use cases.  
    My implementation supports padding with <code>reflect</code>, <code>constant</code>, and <code>edge</code> modes.</p>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part1_1/code_snippet.jpg" alt="Custom Conv2d Code Snippet">
            <div class="caption">Custom Conv2d Code Snippet</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/5094510244632177912.jpg" alt="Original Image">
            <div class="caption">Original Image</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/BOXconv2d.jpg" alt="Custom Convolution Output Box Filter - Sliding Window Conv2d">
            <div class="caption">Custom Convolution Output Box Filter - Sliding Window Conv2d</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/BOXconv2dsimple.jpg" alt="Custom Convolution Output Box Filter - Naive(four for loops) Conv2d">
            <div class="caption">Custom Convolution Output Box Filter - Naive (four for loops)</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/dxSelfie.jpg" alt="Dx Filter Output">
            <div class="caption">Custom Dx Filter - Sliding Window Conv2d</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/dySelfie.jpg" alt="Dy Filter Output">
            <div class="caption">Custom Dy Filter - Sliding Window Conv2d</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_1/scipyimage.jpg" alt="Scipy Convolution Output">
            <div class="caption">Scipy Convolution Output - Box Filter</div>
        </div>
    </div>

    <h3>1.2 Partial Derivatives and Edge Detection</h3>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part1_2/Dx.jpg" alt="Partial Derivative X">
            <div class="caption">Partial Derivative X</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_2/Dy.jpg" alt="Partial Derivative Y">
            <div class="caption">Partial Derivative Y</div>
        </div>
    </div>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part1_2/grad_mag.jpg" alt="Gradient Magnitude">
            <div class="caption">Gradient Magnitude</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_2/edges.jpg" alt="Edges">
            <div class="caption">Edge Map</div>
        </div>
    </div>

    <p>I tuned the threshold to balance edge detection and noise suppression. 85 is the best threshold i found. Any higher and the edges it can find end up breaking up. Any lower and theres a good amount of noise..</p>

    <h3>1.3 Gaussian and DoG Filters</h3>
    <p>
        To reduce noise in edge detection, we first smoothed the image using a <code>cv2.getGaussianKernel</code>-based 2D Gaussian filter. 
        I then computed gradients using finite difference filters (D<sub>x</sub>, D<sub>y</sub>) on the blurred image. 
        This produced much cleaner edge maps than applying derivatives directly to the raw image. I didn't need as high of a threshold value.
    </p>
    <p>
        I also constructed Derivative of Gaussian (DoG) filters by convolving the Gaussian filter with D<sub>x</sub> and D<sub>y</sub> to create DoG<sub>x</sub> and DoG<sub>y</sub>. 
        These were then applied directly to the image in a single convolution step. This approach gave identical results to the two-step method, confirming the linearity of convolution.
    </p>    

    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part1_3/grad_mag.jpg" alt="Gradient Magnitude DoG">
            <div class="caption">Gradient Magnitude (DoG)</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_3/edges.jpg" alt="Edges">
            <div class="caption">Edges (DoG)</div>
        </div>
    </div>

    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part1_3_2/grad_mag.jpg" alt="Gradient Magnitude">
            <div class="caption">Gradient Magnitude (Alt)</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part1_3_2/edges.jpg" alt="Edges">
            <div class="caption">Edges (Alt)</div>
        </div>
    </div>

    <hr>

    <h2>Part 2: Applications</h2>

    <h3>2.1 Unsharp Mask</h3>
    <p>The unsharp mask sharpens an image by amplifying high frequencies. It's computed as: <code>sharpened = original + alpha * (original - blurred)</code>. As you increase the alpha, the edges more prominent. Image 1 is the taj mahal and you can see the edges more amplified. The second set of images, its a little harder to tell but if you look closely the edges are more darker. The third set of images was I test I ran where I took a sharp image blurred it, and then sharpened it again to see if the final sharpened image would be the same as the original image. I found that as long as the standard deviation is the same between the gaussian blur that was done to blur the image, and the gaussian blur used in the sharpen function, the image looks identical between the original and the blur + sharpened image.</p>

    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_1/taj.jpg" alt="Taj Mahal Original">
            <div class="caption">Original: Taj Mahal</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_1/Taj_HighFrequency.jpg" alt="Taj High Frequency">
            <div class="caption">High Frequencies Extracted</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_1/taj_sharpened.jpg" alt="Taj Sharpened">
            <div class="caption">Sharpened Image</div>
        </div>
    </div>

    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_1/20250920_214642.jpg" alt="Original Subject">
            <div class="caption">Original Subject</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_1/20250920_214642_sharpened.jpg" alt="Sharpened">
            <div class="caption">Sharpened Subject</div>
        </div>
    </div>

    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_1/20250621_162424.jpg" alt="Sharp Image">
            <div class="caption">Original Sharp Image</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_1/sharp_blurred.jpg" alt="Blurred">
            <div class="caption">Blurred</div>
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_1/sharp_blurred_sharpened.jpg" alt="Sharpened Again">
            <div class="caption">Sharpened Again</div>
        </div>
    </div>

    <h3>2.2 Hybrid Images</h3>
    <p>Hybrid images combine high-frequency from one image and low-frequency from another. I aligned images, applied Gaussian filters, and tuned sigma values for the high and low frequencies. The first pair of images was provided by CS180. The other sets of images were pictures I had of my friends, I had aligned.</p>

    <h4>Process (Cat + Derek):</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_2/DerekPicture.jpg" alt="Derek">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/nutmeg.jpg" alt="Cat">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/catdudegrey.png" alt="Hybrid Grey">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/catdudecolor.png" alt="Hybrid Color">
        </div>
    </div>

    <h4>Process (David + Jason):</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_2/david.jpeg" alt="David">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/jason.jpeg" alt="Jason">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/JasonDavidv2.png" alt="Hybrid">
        </div>
    </div>

    <h4>Fourier Transforms:</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_2/2_2FFTTable.png" alt="FFT Table">
        </div>
    </div>

    <h4>Process (Jeff + Bush):</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_2/jeffv2.jpg" alt="Jeff">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/bush.jpg" alt="Bush">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/jeffandrewgrey.png" alt="Hybrid Grey">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_2/JeffAndrewcolor.png" alt="Hybrid Color">
        </div>
    </div>

    <h3>2.3 + 2.4 Multiscale Blending</h3>
    <p>I implemented Laplacian pyramid blending. The process uses Gaussian and Laplacian stacks of both images and the mask. I created a vertical and circular mask. I modified my Conv2d method from part 1 to support convolutions for color images. In order to create a smoother blending, I modifed the mask to have a blend width which transition the values smoother from 1 to 0, from each side of the mask. In addition I increase the sigma value of the gaussian kernel as I created more stacks. This made the blending process smoother.</p>

    <h4>Apple + Orange (Figure 3.42 Replication):</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_3_4/2_3_4 sTACKS.png" alt="Stacks">
        </div>
    </div>

    <h4>Final Orange Apple Blend:</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_3_4/orange.jpeg" alt="Orange">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/apple.jpeg" alt="Apple">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/orapleFinal.png" alt="Blended Result">
        </div>
    </div>

    <h4>Dodge Charger White and Silver:</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_3_4/dodgesilver.jpg" alt="Silver">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/dodgewhite.jpg" alt="White">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/dodgesilverwhiteblended.png" alt="Blended">
        </div>
    </div>

    <h4>Earth and Mars (Circular Mask):</h4>
    <div class="img-row">
        <div class="img-container">
            <img src="outputimgs/part2_3_4/earth.jpeg" alt="Earth">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/mars.jpg" alt="Mars">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/earthMarsblendedv2.png" alt="Blended 1">
        </div>
        <div class="img-container">
            <img src="outputimgs/part2_3_4/earthMarsCircularBlendedv2.jpg" alt="Blended 2">
        </div>
    </div>
    <p>This blend uses an circular mask. I changed the radius ratio between the Earth and Mars between both images </p>

</body>
</html>
